{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: memorize the $Q$ function qua [Model-Free Episodic Control](https://arxiv.org/abs/1606.04460)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMT API\n",
    "\n",
    "From the paper we have:\n",
    "\n",
    "1. $(u, z) \\leftarrow \\text{Query}(x)$ where $z = \\{ (x_n, \\omega_n) \\}$ is an ordered set of retrieved key-value pairs.\n",
    "1. $\\text{Update}(x, (x_n, \\omega_n), r, u)$ provides feedback reward $r$ for retrieval of $(x_n, \\omega_n)$ for query $x$.\n",
    "   1. Must be compatible with self-consistency or supervised and unsupervised updates conflict.\n",
    "1. $\\text{Insert}(x, \\omega)$ creates a new memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     1,
     2,
     11,
     25,
     38,
     48,
     56,
     61,
     83,
     94,
     110,
     120,
     129,
     143,
     162,
     195,
     234,
     262
    ]
   },
   "outputs": [],
   "source": [
    "class CMT:\n",
    "    class Node:\n",
    "        def __init__(self, parent, left=None, right=None, g=None):\n",
    "            self.parent = parent\n",
    "            self.isLeaf = left is None\n",
    "            self.n = 0        \n",
    "            self.memories = {}\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.g = g\n",
    "            \n",
    "        def makeInternal(self, g):       \n",
    "            assert self.isLeaf\n",
    "            \n",
    "            self.isLeaf = False\n",
    "            self.left = CMT.Node(parent=self)\n",
    "            self.right = CMT.Node(parent=self)\n",
    "            self.n = 0\n",
    "            self.g = g\n",
    "            \n",
    "            mem = self.memories\n",
    "            self.memories = {}\n",
    "            \n",
    "            return mem\n",
    "        \n",
    "        def replaceNode(self, replacement):\n",
    "            if self is not replacement:\n",
    "                self.isLeaf = replacement.isLeaf\n",
    "                self.n = replacement.n\n",
    "                self.memories = replacement.memories\n",
    "                self.left = replacement.left\n",
    "                if self.left:\n",
    "                    self.left.parent = self\n",
    "                self.right = replacement.right\n",
    "                if self.right:\n",
    "                    self.right.parent = self\n",
    "                self.g = replacement.g\n",
    "\n",
    "        def topk(self, x, k, f):\n",
    "            assert self.isLeaf\n",
    "            return [ z for _, z in zip(range(k), \n",
    "                                       sorted(self.memories.items(),\n",
    "                                              key=lambda z: f.predict(x, z),\n",
    "                                              reverse=True\n",
    "                                             )\n",
    "                                      ) \n",
    "                   ]\n",
    "        \n",
    "        def randk(self, k, randomState):\n",
    "            assert self.isLeaf\n",
    "            return [ z[1] for _, z in zip(range(k),\n",
    "                                          sorted( (randomState.uniform(0, 1), m) for m in self.memories.items() \n",
    "                                                )\n",
    "                                      )\n",
    "                   ]\n",
    "    \n",
    "    class Path:\n",
    "        def __init__(self, nodes, leaf):\n",
    "            self.nodes = nodes\n",
    "            self.leaf = leaf\n",
    "    \n",
    "    class LRU:\n",
    "        def __init__(self):\n",
    "            self.entries = []\n",
    "            self.entry_finder = set()\n",
    "            self.n = 0\n",
    "        \n",
    "        def add(self, x):\n",
    "            from heapq import heappush\n",
    "            \n",
    "            assert x not in self.entry_finder\n",
    "            \n",
    "            entry = (self.n, x)\n",
    "            self.entry_finder.add(x)\n",
    "            heappush(self.entries, entry)\n",
    "            self.n += 1\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.entry_finder)\n",
    "        \n",
    "        def __contains__(self, x):\n",
    "            return x in self.entry_finder\n",
    "        \n",
    "        def peek(self):\n",
    "            from heapq import heappop\n",
    "            \n",
    "            while self.entries[0][1] not in self.entry_finder:\n",
    "                heappop(self.entries)\n",
    "                \n",
    "            return self.entries[0][1]\n",
    "        \n",
    "        def remove(self, x):\n",
    "            self.entry_finder.remove(x)\n",
    "    \n",
    "    def __init__(self, routerFactory, scorer, alpha, c, d, randomState, maxMemories=None):\n",
    "        self.routerFactory = routerFactory\n",
    "        self.f = scorer\n",
    "        self.alpha = alpha\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "        self.leafbykey = {}\n",
    "        self.root = CMT.Node(None)\n",
    "        self.randomState = randomState        \n",
    "        self.allkeys = []\n",
    "        self.allkeysindex = {}\n",
    "        self.maxMemories = maxMemories \n",
    "        self.keyslru = CMT.LRU()\n",
    "        self.rerouting = False\n",
    "        self.splitting = False\n",
    "\n",
    "    def nodeForeach(self, f, node=None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "            \n",
    "        f(node)\n",
    "        if node.left:\n",
    "            self.nodeForeach(f, node.left)\n",
    "        if node.right:\n",
    "            self.nodeForeach(f, node.right)\n",
    "        \n",
    "    def __path(self, x, v):          \n",
    "        nodes = []\n",
    "        while not v.isLeaf:\n",
    "            a = v.right if v.g.predict(x) > 0 else v.left\n",
    "            nodes.append(v)\n",
    "            v = a\n",
    "            \n",
    "        return CMT.Path(nodes, v)\n",
    "        \n",
    "    def query(self, x, k, epsilon):\n",
    "        path = self.__path(x, self.root)\n",
    "        q = self.randomState.uniform(0, 1)\n",
    "        if q >= epsilon:\n",
    "            return (None, path.leaf.topk(x, k, self.f))\n",
    "        else:\n",
    "            i = self.randomState.randint(0, len(path.nodes))\n",
    "            if i < len(path.nodes):\n",
    "                a = self.randomState.choice( (path.nodes[i].left, path.nodes[i].right) )\n",
    "                l = self.__path(x, a).leaf\n",
    "                return ((path.nodes[i], a, 1/2), l.topk(x, k, self.f))\n",
    "            else:\n",
    "                return ((path.leaf, None, None), path.leaf.randk(k, self.randomState))\n",
    "            \n",
    "    def update(self, u, x, z, r):\n",
    "        if u is None:\n",
    "            pass\n",
    "        else:\n",
    "            (v, a, p) = u\n",
    "            if v.isLeaf:\n",
    "                self.f.update(x, z, r)\n",
    "            else:\n",
    "                from math import log\n",
    "\n",
    "                rhat = (r/p) * (1 if a == v.right else -1)\n",
    "                y = (1 - self.alpha) * rhat + self.alpha * (log(1e-2 + v.left.n) - log(1e-2 + v.right.n)) \n",
    "                signy = 1 if y > 0 else -1\n",
    "                absy = signy * y\n",
    "                v.g.update(x, signy, absy)\n",
    "                \n",
    "            for _ in range(self.d):\n",
    "                self.__reroute()\n",
    "                \n",
    "    def delete(self, x):\n",
    "        if x not in self.allkeysindex:\n",
    "            # deleting something not in the memory ...\n",
    "            assert False\n",
    "                    \n",
    "        ind = self.allkeysindex.pop(x)\n",
    "        lastx = self.allkeys.pop()\n",
    "        if ind < len(self.allkeys):\n",
    "            self.allkeys[ind] = lastx\n",
    "            self.allkeysindex[lastx] = ind\n",
    "                \n",
    "        if not self.rerouting:\n",
    "            self.keyslru.remove(x)\n",
    "                \n",
    "        v = self.leafbykey.pop(x)\n",
    "        \n",
    "        while v is not None:\n",
    "            v.n -= 1\n",
    "            if v.isLeaf:\n",
    "                omega = v.memories.pop(x)\n",
    "            else:\n",
    "                if v.n == 0:\n",
    "                    other = v.parent.left if v is v.parent.right else v.parent.right\n",
    "                    if other.isLeaf:\n",
    "                        for xprime in other.memories.keys():\n",
    "                            self.leafbykey[xprime] = v.parent\n",
    "\n",
    "                    v.parent.replaceNode(other)\n",
    "                    v = v.parent\n",
    "                    \n",
    "            assert v.n >= 0\n",
    "            v = v.parent\n",
    "            \n",
    "    def __insertLeaf(self, x, omega, v):\n",
    "        from math import log\n",
    "        \n",
    "        assert v.isLeaf\n",
    "\n",
    "        if x not in self.allkeysindex:          \n",
    "            self.allkeysindex[x] = len(self.allkeys)\n",
    "            self.allkeys.append(x)\n",
    "        \n",
    "        if not self.rerouting and not self.splitting:\n",
    "            self.keyslru.add(x)\n",
    "                        \n",
    "        if self.splitting or v.n < self.c:\n",
    "            assert x not in self.leafbykey\n",
    "            self.leafbykey[x] = v\n",
    "            assert x not in v.memories\n",
    "            v.memories[x] = omega\n",
    "            v.n += 1\n",
    "            assert v.n == len(v.memories)\n",
    "        else:\n",
    "            self.splitting = True\n",
    "            mem = v.makeInternal(g=self.routerFactory())\n",
    "            \n",
    "            while mem:\n",
    "                xprime, omegaprime = mem.popitem()\n",
    "                del self.leafbykey[xprime]\n",
    "                self.insert(xprime, omegaprime, v)\n",
    "                \n",
    "            self.insert(x, omega, v)\n",
    "            self.splitting = False\n",
    "            \n",
    "        if not self.rerouting and not self.splitting:\n",
    "            daleaf = self.leafbykey[x]\n",
    "            dabest = daleaf.topk(x, 2, self.f)\n",
    "            if len(dabest) > 1:\n",
    "                other = dabest[1] if dabest[0][0] == x else dabest[0] \n",
    "                z = [(x, omega), other]\n",
    "                self.f.update(x, z, 1)\n",
    "                     \n",
    "    def insert(self, x, omega, v=None):\n",
    "        from math import log\n",
    "        \n",
    "        if x in self.leafbykey:\n",
    "            # duplicate memory ... need to merge values ...\n",
    "            assert False\n",
    "            \n",
    "        if v is None:\n",
    "            v = self.root\n",
    "        \n",
    "        while not v.isLeaf:\n",
    "            B = log(1e-2 + v.left.n) - log(1e-2 + v.right.n)\n",
    "            y = (1 - self.alpha) * v.g.predict(x) + self.alpha * B\n",
    "            signy = 1 if y > 0 else -1\n",
    "            v.g.update(x, signy, 1)\n",
    "            v.n += 1\n",
    "            v = v.right if v.g.predict(x) > 0 else v.left\n",
    "            \n",
    "        self.__insertLeaf(x, omega, v)\n",
    "        \n",
    "        if not self.rerouting and not self.splitting:\n",
    "            if self.maxMemories is not None and len(self.keyslru) > self.maxMemories:\n",
    "                oldest = self.keyslru.peek()\n",
    "                self.delete(oldest)\n",
    "\n",
    "            for _ in range(self.d):\n",
    "                self.__reroute()\n",
    "                            \n",
    "    def __reroute(self):\n",
    "        x = self.randomState.choice(self.allkeys)\n",
    "        omega = self.leafbykey[x].memories[x]\n",
    "        self.rerouting = True\n",
    "        self.delete(x)\n",
    "        self.insert(x, omega)\n",
    "        self.rerouting = False\n",
    "        \n",
    "        for k in self.leafbykey.keys():\n",
    "            assert k in self.leafbykey[k].memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     1,
     7,
     17,
     36,
     44,
     48,
     57,
     66,
     102,
     128
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structureValid test pass\n",
      "selfconsistent test pass\n",
      "maxmemories test pass\n"
     ]
    }
   ],
   "source": [
    "class CMTTests:\n",
    "    class LinearModel:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            from sklearn import linear_model\n",
    "            \n",
    "            self.model = linear_model.SGDRegressor(*args, **kwargs)\n",
    "            \n",
    "        def predict(self, x):\n",
    "            from sklearn.exceptions import NotFittedError \n",
    "            try:\n",
    "                return self.model.predict(X=[x])[0]\n",
    "            except NotFittedError:\n",
    "                return 0\n",
    "        \n",
    "        def update(self, x, y, w):\n",
    "            self.model.partial_fit(X=[x], y=[y], sample_weight=[w])\n",
    "            \n",
    "    class NormalizedLinearProduct:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "        def predict(self, x, z):\n",
    "            import numpy as np\n",
    "            from math import sqrt\n",
    "            \n",
    "            (xprime, omegaprime) = z\n",
    "            \n",
    "            xa = np.array(x)\n",
    "            xprimea = np.array(xprime)\n",
    "                        \n",
    "            return np.inner(xa, xprimea) / sqrt(np.inner(xa, xa) * np.inner(xprimea, xprimea))\n",
    "        \n",
    "        def update(self, x, y, w):\n",
    "            pass\n",
    " \n",
    "    @staticmethod\n",
    "    def displaynode(node, indent):\n",
    "        if node is not None:\n",
    "            from pprint import pformat\n",
    "            print(indent, pformat((node, node.__dict__)))\n",
    "            CMTTests.displaynode(node.left, indent + \"*\")\n",
    "            CMTTests.displaynode(node.right, indent + \"*\")\n",
    "\n",
    "    @staticmethod\n",
    "    def displaytree(cmt):\n",
    "        CMTTests.displaynode(cmt.root, indent=\"\")\n",
    "\n",
    "    @staticmethod\n",
    "    def structureValid():\n",
    "        import random\n",
    "        \n",
    "        routerFactory = lambda: CMTTests.LinearModel()\n",
    "        scorer = CMTTests.NormalizedLinearProduct()\n",
    "        randomState = random.Random()\n",
    "        randomState.seed(2112)\n",
    "        cmt = CMT(routerFactory=routerFactory, scorer=scorer, alpha=0.5, c=10, d=0, randomState=randomState)\n",
    "\n",
    "        def checkNodeInvariants(node):\n",
    "            assert node.parent is None or node.parent.left is node or node.parent.right is node\n",
    "            assert node.left is None or node.n == node.left.n + node.right.n\n",
    "            assert node.left is None or node.left.parent is node\n",
    "            assert node.right is None or node.right.parent is node\n",
    "            assert node.left is not None or node.n == len(node.memories)\n",
    "    \n",
    "        stuff = {}\n",
    "        \n",
    "        for _ in range(200):\n",
    "            try:\n",
    "                if stuff and randomState.uniform(0, 1) < 0.1:\n",
    "                    # delete\n",
    "                    x, omega = stuff.popitem()\n",
    "                    cmt.delete(x)\n",
    "                elif stuff and randomState.uniform(0, 1) < 0.1:\n",
    "                    # query/update\n",
    "                    somex = randomState.choice(list(stuff.keys()))\n",
    "                    u, z = cmt.query(x, 1, 0.1)\n",
    "                    cmt.update(u, x, z, randomState.uniform(0, 1))\n",
    "                else:\n",
    "                    # insert\n",
    "                    x = tuple([ randomState.uniform(0, 1) for _ in range(3)])\n",
    "                    omega = randomState.uniform(0, 1)\n",
    "                    cmt.insert(x, omega)\n",
    "                    stuff[x] = omega\n",
    "\n",
    "                assert cmt.root.n == len(stuff)\n",
    "                assert cmt.root.n == len(cmt.leafbykey)\n",
    "                assert cmt.root.n == len(cmt.allkeys)\n",
    "                assert cmt.root.n == len(cmt.allkeysindex)\n",
    "                for x in stuff.keys():\n",
    "                    assert x in cmt.leafbykey[x].memories\n",
    "                    assert x in cmt.allkeysindex\n",
    "                    assert cmt.allkeys[cmt.allkeysindex[x]] is x\n",
    "                cmt.nodeForeach(checkNodeInvariants)\n",
    "            except:\n",
    "                print(\"--------------\")\n",
    "                CMTTests.displaytree(cmt)\n",
    "                print(\"--------------\")\n",
    "                raise\n",
    "                \n",
    "        print('structureValid test pass')           \n",
    "                       \n",
    "    @staticmethod\n",
    "    def selfconsistent():\n",
    "        import random\n",
    "        \n",
    "        routerFactory = lambda: CMTTests.LinearModel()\n",
    "        scorer = CMTTests.NormalizedLinearProduct()\n",
    "        randomState = random.Random()\n",
    "        randomState.seed(45)\n",
    "        cmt = CMT(routerFactory=routerFactory, scorer=scorer, alpha=0.5, c=10, d=0, randomState=randomState)\n",
    "        \n",
    "        for _ in range(200):\n",
    "            try:\n",
    "                x = tuple([ randomState.uniform(0, 1) for _ in range(3)])\n",
    "                omega = randomState.uniform(0, 1)\n",
    "\n",
    "                cmt.insert(x, omega)\n",
    "                u, [ (xprime, omegaprime) ] = cmt.query(x, k=1, epsilon=0)\n",
    "                assert omega == omegaprime, '({}, [({}, {})]) = cmt.query({}) != {}'.format(u, xprime, omegaprime, x, omega)\n",
    "            except:\n",
    "                print(\"--------------\")\n",
    "                CMTTests.displaytree(cmt)\n",
    "                print(\"--------------\")\n",
    "                raise\n",
    "                \n",
    "        print('selfconsistent test pass')\n",
    "        \n",
    "    @staticmethod\n",
    "    def maxmemories():\n",
    "        import random\n",
    "        \n",
    "        routerFactory = lambda: CMTTests.LinearModel()\n",
    "        scorer = CMTTests.NormalizedLinearProduct()\n",
    "        randomState = random.Random()\n",
    "        randomState.seed(45)\n",
    "        maxM = 100\n",
    "        cmt = CMT(routerFactory=routerFactory, scorer=scorer, alpha=0.5, c=10, d=0, randomState=randomState, maxMemories=maxM)\n",
    "        \n",
    "        for _ in range(200):\n",
    "            try:\n",
    "                x = tuple([ randomState.uniform(0, 1) for _ in range(3)])\n",
    "                omega = randomState.uniform(0, 1)\n",
    "\n",
    "                cmt.insert(x, omega)\n",
    "                assert len(cmt.leafbykey) <= maxM\n",
    "            except:\n",
    "                print(\"--------------\")\n",
    "                CMTTests.displaytree(cmt)\n",
    "                print(\"--------------\")\n",
    "                raise\n",
    "                \n",
    "        print('maxmemories test pass')\n",
    "       \n",
    "    @staticmethod\n",
    "    def all():\n",
    "        CMTTests.structureValid()\n",
    "        CMTTests.selfconsistent()\n",
    "        CMTTests.maxmemories()\n",
    "\n",
    "CMTTests().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value difference from deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Supervised Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose queries are drawn IID from $D$, every query is followed by an update, and we have a fixed CMT we are operating in greedy mode.   Then the expected reward for the CMT is \n",
    "$$\n",
    "V(\\text{CMT}) = \\mathbb{E}_{\\substack{x \\sim D \\\\ z \\sim \\text{CMT}(x) \\\\ r \\sim \\text{Update}(x, z)}}\\left[ 1^\\top r \\right]\n",
    "$$\n",
    "Note the reward on $z$ is the sum over the rewards on each returned item (NB: this structure is forced upon us by the update call).\n",
    "Suppose now we delete meme $\\alpha$ from the system, denote the resulting tree $\\text{CMT}_{\\setminus \\alpha}$.  The reward is conditionally independent of the CMT given $z$, therefore $$\n",
    "\\begin{aligned}\n",
    "V\\left( \\text{CMT}_{\\setminus \\alpha} \\right) &= \\mathbb{E}_{\\substack{x \\sim D \\\\ z_{\\setminus \\alpha} \\sim \\text{CMT}_{\\setminus \\alpha}(x) \\\\ r_{\\setminus \\alpha} \\sim \\text{Update}(x, z_{\\setminus \\alpha})}}\\left[ 1^\\top r_{\\setminus \\alpha} \\right] \\\\\n",
    "\\Delta V(\\alpha) \\doteq V(\\text{CMT}) - V\\left( \\text{CMT}_{\\setminus \\alpha} \\right) &= \\mathbb{E}_{\\substack{x \\sim D \\\\ z \\sim \\text{CMT}(x) \\\\ z_{\\setminus \\alpha} \\sim \\text{CMT}_{\\setminus \\alpha}(x) \\\\ r \\sim \\text{Update}(x, z) \\\\ r_{\\setminus \\alpha} \\sim \\text{Update}(x, z_{\\setminus \\alpha})}}\\left[ 1^\\top (r - r_{\\setminus \\alpha}) 1_{z \\neq z_{\\setminus \\alpha}} \\right] \\\\\n",
    "\\end{aligned}\n",
    "$$ For a particular query $x$, if $\\alpha \\not \\in z$ than $z = z_{\\setminus \\alpha}$.  So to estimate the value difference from deletion we only need to consider queries whose retrieval contains $\\alpha$.  Therefore, delta in reward when $\\alpha \\in z$ is ($\\mathbb{E}\\left[r | x, \\alpha \\right]$ - $\\mathbb{E}\\left[r | x, \\text{k+1}^\\text{th}\\right]$) where $\\mathbb{E}\\left[r | x, \\text{k+1}^\\text{th}\\right]$ is the estimated value of the \"first meme not returned in greedy mode\".  How to estimate (a lower bound on) this?\n",
    "\n",
    "* **Idea**: Approximate $\\mathbb{E}\\left[r | x, \\alpha\\right] \\approx \\mathbb{E}\\left[r | \\text{leaf}(x), \\alpha \\right]$.\n",
    "   * For each meme, maintain a scalar (CI) reward conditional on retrieval.\n",
    "   * A valuable memory: \n",
    "       1. Is frequently retrieved, and\n",
    "       1. Has a high reward conditioned upon being retrieved, and\n",
    "       1. The $\\text{k+1}^\\text{th}$ meme in the same leaf has low reward conditioned on being retrieved.\n",
    "       1. $\\Delta V(\\alpha) = \\mathrm{Pr}(\\text{$\\alpha$ retrieved}) \\left( \\mathbb{E}\\left[r | \\text{leaf}(x), \\alpha \\right] - \\mathbb{E}\\left[r | \\text{leaf}(x), \\text{k+1}^\\text{th}\\right]\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partially Supervised or Unsupervised Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote an &ldquo;no-update&rdquo; reward as $\\emptyset$ so that rewards are always specified. Suppose updates are missing at random such that $\\mathbb{E}\\left[r 1_{r \\neq \\emptyset} | x, \\alpha\\right] = \\mathbb{E}\\left[r | x, \\alpha, r \\neq \\emptyset\\right] \\mathbb{E}\\left[1_{r \\neq \\emptyset}\\right]$.  Then it makes sense to condition on $r \\neq \\emptyset$ and apply the fully supervised strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Unsupervised Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we only know two things:\n",
    "1. Exact match retrieval is presumed to have maximum $r = 1$. \n",
    "1. Each insert comes with an implicit exact match update.\n",
    "\n",
    "Therefore, if contexts never repeat all memories have the same estimated value (everybody has exactly 1 update with $r = 1$) and all memes have equal value, suggesting at-random deletion is a good strategy.\n",
    "\n",
    "If contexts repeat than the CI for a frequently exactly matched meme  will be tighter below $r = 1$ than for an infrequently exactly matched meme, in which case the least frequently exactly matched meme is best to delete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fully Observed Covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     15,
     57
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 283301, 0: 211840, 2: 35754, 6: 20510, 5: 17367, 4: 9493, 3: 2747})\n",
      "*** lr = 0.1 ***\n",
      "n       \temp loss\tsince last\tpred      \n",
      "64      \t0.641   \t0.641     \t3         \n",
      "96      \t0.625   \t0.594     \t4         \n",
      "160     \t0.656   \t0.703     \t6         \n",
      "288     \t0.615   \t0.562     \t1         \n",
      "544     \t0.570   \t0.520     \t1         \n",
      "1056    \t0.518   \t0.463     \t1         \n",
      "2080    \t0.455   \t0.391     \t6         \n",
      "4128    \t0.405   \t0.354     \t2         \n",
      "8224    \t0.365   \t0.324     \t0         \n",
      "16416   \t0.332   \t0.300     \t0         \n",
      "32800   \t0.312   \t0.291     \t0         \n",
      "65568   \t0.301   \t0.290     \t1         \n",
      "131104  \t0.293   \t0.286     \t0         \n",
      "262176  \t0.289   \t0.285     \t1         \n",
      "522880  \t0.287   \t0.284     \t0         \n",
      "Counter({1: 30335, 0: 20781, 2: 4847, 6: 1503, 5: 422, 3: 202, 4: 11})\n",
      "test accuracy: [0.71633449 0.71908401 0.7219368 ]\n",
      "19.190191100002266\n"
     ]
    }
   ],
   "source": [
    "class FOC:\n",
    "    class EasyAcc:\n",
    "        def __init__(self):\n",
    "            self.n = 0\n",
    "            self.sum = 0\n",
    "            \n",
    "        def __iadd__(self, other):\n",
    "            self.n += 1\n",
    "            self.sum += other\n",
    "            return self\n",
    "            \n",
    "        def mean(self):\n",
    "            return self.sum / max(self.n, 1)\n",
    "\n",
    "    import torch\n",
    "    class LogisticRegressor(torch.nn.Module):        \n",
    "        def __init__(self, input_dim, output_dim, eta0=0.1):\n",
    "            import torch\n",
    "            \n",
    "            super(FOC.LogisticRegressor, self).__init__()\n",
    "            self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "            self.optimizer = torch.optim.Adam(self.linear.parameters(), lr=eta0)\n",
    "            self.eta0 = eta0\n",
    "            self.n = 0\n",
    "            \n",
    "        def forward(self, x):\n",
    "            import numpy as np\n",
    "            import torch\n",
    "\n",
    "            return self.linear(torch.autograd.Variable(torch.from_numpy(x)))\n",
    "        \n",
    "        def predict(self, X):\n",
    "            import torch\n",
    "            \n",
    "            return torch.argmax(self.forward(X), dim=1).numpy()\n",
    "        \n",
    "        def set_lr(self):\n",
    "            from math import sqrt\n",
    "            lr = self.eta0 / sqrt(self.n)\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = lr\n",
    "            \n",
    "        def partial_fit(self, X, y, sample_weight=None, **kwargs):\n",
    "            import torch\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            yhat = self.forward(X)\n",
    "            if sample_weight is None:\n",
    "                loss = self.loss(yhat, torch.from_numpy(y))\n",
    "            else:\n",
    "                loss = sample_weight * self.loss(yhat, torch.from_numpy(y))\n",
    "            loss.backward()\n",
    "            self.n += X.shape[0]\n",
    "            self.set_lr()\n",
    "            self.optimizer.step() \n",
    "        \n",
    "    def doit():\n",
    "        from collections import Counter\n",
    "        from sklearn.datasets import fetch_covtype\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from math import ceil\n",
    "        import numpy as np\n",
    "\n",
    "        cov = fetch_covtype()\n",
    "        cov.data = PCA(whiten=True).fit_transform(cov.data).astype(np.float32)\n",
    "        classes = np.unique(cov.target - 1)\n",
    "        print(Counter(cov.target - 1))\n",
    "        ndata = len(cov.target)\n",
    "        order = np.random.RandomState(seed=42).permutation(ndata)\n",
    "        ntrain = ceil(0.9 * ndata)\n",
    "        Object = lambda **kwargs: type(\"Object\", (), kwargs)()\n",
    "        train = Object(data = cov.data[order[:ntrain]], target = cov.target[order[:ntrain]] - 1)\n",
    "        test = Object(data = cov.data[order[ntrain:]], target = cov.target[order[ntrain:]] - 1)\n",
    "\n",
    "        blocksize = 32\n",
    "        for lr in [0.1]:\n",
    "            print(\"*** lr = {} ***\".format(lr), flush=True)\n",
    "            print('{:8.8s}\\t{:8.8s}\\t{:10.10s}\\t{:10.10s}'.format(\n",
    "                'n', 'emp loss', 'since last', 'pred')\n",
    "            )\n",
    "            \n",
    "            input_dim = train.data[0].shape[0]\n",
    "            cls = FOC.LogisticRegressor(input_dim, output_dim=len(classes), eta0=lr)\n",
    "#             cls = SGDClassifier(loss='log', shuffle=False, learning_rate='invscaling', eta0=lr)\n",
    "            loss = FOC.EasyAcc()\n",
    "            sincelast = FOC.EasyAcc()\n",
    "\n",
    "            for pno in range(1):\n",
    "                order = np.random.RandomState(seed=42+pno).permutation(len(train.data))\n",
    "                for n, ind in enumerate(zip(*(iter(order),)*blocksize)):\n",
    "                    v = np.array([ t\n",
    "                                   for z in ind for t in ( train.data[z], ) ],\n",
    "                                 dtype='float32')\n",
    "                    actual = np.array([ train.target[z] for z in ind ], dtype='int')\n",
    "                    if n == 0:\n",
    "                        for a in actual:\n",
    "                            loss += 0 if a == 0 else 1\n",
    "                            sincelast += 0 if a == 0 else 1\n",
    "                    if n > 0:\n",
    "                        pred = cls.predict(v)\n",
    "                        for p, a in zip(pred, actual):\n",
    "                            loss += 0 if p == a else 1\n",
    "                            sincelast += 0 if p == a else 1  \n",
    "\n",
    "                        if (n & (n - 1) == 0): # and n & 0xAAAAAAAA == 0):\n",
    "                            print('{:<8d}\\t{:<8.3f}\\t{:<10.3f}\\t{:<10d}'.format(\n",
    "                                        loss.n, loss.mean(), sincelast.mean(), pred[-1]),\n",
    "                                  flush=True)\n",
    "\n",
    "                            sincelast = FOC.EasyAcc()\n",
    "\n",
    "                    cls.partial_fit(v, actual, classes=classes)\n",
    "\n",
    "                print('{:<8d}\\t{:<8.3f}\\t{:<10.3f}\\t{:<10d}'.format(\n",
    "                             loss.n, loss.mean(), sincelast.mean(), pred[-1]),\n",
    "                       flush=True)                \n",
    "                sincelast = FOC.EasyAcc()\n",
    "\n",
    "                preds = cls.predict(test.data.astype('float32'))\n",
    "                print(Counter(preds))\n",
    "                ascores = []\n",
    "                for b in range(16):\n",
    "                    bootie = np.random.RandomState(90210+b).choice(len(test.target), replace=True, size=len(test.target))\n",
    "                    ascores.append(accuracy_score(y_true=test.target[bootie], y_pred=preds[bootie]))\n",
    "\n",
    "                print(\"test accuracy: {}\".format(np.quantile(ascores, [0.05, 0.5, 0.95])))\n",
    "\n",
    "def flass():\n",
    "    import timeit\n",
    "    print(timeit.timeit(FOC.doit, number=1))\n",
    "    \n",
    "flass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Contextual Memory Tree (Linear Routers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1,
     15,
     26,
     57
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 283301, 0: 211840, 2: 35754, 6: 20510, 5: 17367, 4: 9493, 3: 2747})\n",
      "n       \temp loss\tsince last\tlast pred \n",
      "1       \t1.000   \t1.000     \t0         \n",
      "2       \t1.000   \t1.000     \t6         \n",
      "3       \t1.000   \t1.000     \t6         \n",
      "5       \t0.800   \t0.500     \t0         \n",
      "9       \t0.556   \t0.250     \t1         \n",
      "17      \t0.588   \t0.625     \t1         \n",
      "33      \t0.515   \t0.438     \t6         \n",
      "65      \t0.523   \t0.531     \t1         \n",
      "129     \t0.426   \t0.328     \t1         \n",
      "257     \t0.440   \t0.453     \t1         \n",
      "513     \t0.427   \t0.414     \t1         \n",
      "1025    \t0.390   \t0.354     \t1         \n",
      "2049    \t0.370   \t0.351     \t0         \n",
      "4097    \t0.373   \t0.376     \t1         \n",
      "8193    \t0.363   \t0.352     \t2         \n",
      "16385   \t0.359   \t0.355     \t6         \n",
      "32769   \t0.362   \t0.365     \t0         \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-36de756e48bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m \u001b[0mflass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-36de756e48bc>\u001b[0m in \u001b[0;36mflass\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mflass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0mflass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    231\u001b[0m            number=default_number, globals=None):\n\u001b[1;32m    232\u001b[0m     \u001b[0;34m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-36de756e48bc>\u001b[0m in \u001b[0;36mdoit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                         \u001b[0mcmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mcmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             print('{:<8d}\\t{:<8.3f}\\t{:<10.3f}\\t{:<10d}'.format(\n",
      "\u001b[0;32m<ipython-input-3-503f424b4139>\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, x, omega, v)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0msigny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-36de756e48bc>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, x, y, w)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             self.model.partial_fit(X=np.array([x], dtype='float32'), \n\u001b[0m\u001b[1;32m     76\u001b[0m                                    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-36de756e48bc>\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mLogisticModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ope/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0maccumulate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0minto\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \"\"\"\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"retains_grad\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n\u001b[1;32m    747\u001b[0m                           \u001b[0;34m\"attribute won't be populated during autograd.backward(). If you indeed want the gradient \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class FOC:\n",
    "    class EasyAcc:\n",
    "        def __init__(self):\n",
    "            self.n = 0\n",
    "            self.sum = 0\n",
    "            \n",
    "        def __iadd__(self, other):\n",
    "            self.n += 1\n",
    "            self.sum += other\n",
    "            return self\n",
    "            \n",
    "        def mean(self):\n",
    "            return self.sum / max(self.n, 1)\n",
    "\n",
    "    import torch\n",
    "    class LogisticRegressor(torch.nn.Module):        \n",
    "        def __init__(self, input_dim, output_dim, eta0):\n",
    "            import torch\n",
    "            \n",
    "            super(FOC.LogisticRegressor, self).__init__()\n",
    "            self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "            self.optimizer = torch.optim.Adam(self.linear.parameters(), lr=eta0)\n",
    "            self.eta0 = eta0\n",
    "            self.n = 0\n",
    "            \n",
    "        def forward(self, X):\n",
    "            import numpy as np\n",
    "            import torch\n",
    "\n",
    "            return self.linear(torch.autograd.Variable(torch.from_numpy(X)))\n",
    "        \n",
    "        def predict(self, X):\n",
    "            import torch\n",
    "            \n",
    "            return torch.argmax(self.forward(X), dim=1).numpy()\n",
    "        \n",
    "        def set_lr(self):\n",
    "            from math import sqrt\n",
    "            lr = self.eta0 / sqrt(self.n)\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = lr\n",
    "\n",
    "        def partial_fit(self, X, y, sample_weight=None, **kwargs):\n",
    "            import torch\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            yhat = self.forward(X)\n",
    "            if sample_weight is None:\n",
    "                loss = self.loss(yhat, torch.from_numpy(y))\n",
    "            else:\n",
    "                loss = torch.from_numpy(sample_weight) * self.loss(yhat, torch.from_numpy(y))\n",
    "            loss.backward()\n",
    "            self.n += X.shape[0]\n",
    "            self.set_lr()\n",
    "            self.optimizer.step() \n",
    "\n",
    "    class LogisticModel:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            kwargs['output_dim'] = 2\n",
    "            self.model = FOC.LogisticRegressor(*args, **kwargs)\n",
    "            \n",
    "        def predict(self, x):\n",
    "            import numpy as np\n",
    "            \n",
    "            F = self.model.forward(X=np.array([x], dtype='float32')).detach().numpy()\n",
    "            dF = F[:,1] - F[:,0]\n",
    "            return -1 + 2 * dF          \n",
    "        \n",
    "        def update(self, x, y, w):\n",
    "            import numpy as np\n",
    "            \n",
    "            assert y == 1 or y == -1\n",
    "            \n",
    "            self.model.partial_fit(X=np.array([x], dtype='float32'), \n",
    "                                   y=(1 + np.array([y], dtype='int')) // 2, \n",
    "                                   sample_weight=np.array([w], dtype='float32'),\n",
    "                                   classes=(0, 1))\n",
    "\n",
    "    class LearnedEuclideanDistance:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            kwargs['output_dim'] = 2\n",
    "            self.model = FOC.LogisticRegressor(*args, **kwargs)\n",
    "            self.model.linear.weight.data[0,:].fill_(0.01 / kwargs['input_dim'])\n",
    "            self.model.linear.weight.data[1,:].fill_(-0.01 / kwargs['input_dim'])\n",
    "            self.model.linear.bias.data.fill_(0.0)\n",
    "            self.model.linear.bias.requires_grad = False\n",
    "        \n",
    "        def predict(self, x, z):\n",
    "            import numpy as np\n",
    "            \n",
    "            (xprime, omegaprime) = z\n",
    "            \n",
    "            dx = np.array([x], dtype='float32')\n",
    "            dx -= [xprime]\n",
    "            dx *= dx\n",
    "            \n",
    "            F = self.model.forward(dx).detach().numpy()\n",
    "            dist = F[0,1] - F[0,0]\n",
    "            return dist\n",
    "        \n",
    "        def update(self, x, z, r):\n",
    "            import numpy as np\n",
    "            \n",
    "            if r == 1 and len(z) > 1 and z[0][1] != z[1][1]:\n",
    "                dx = np.array([ z[0][0], z[1][0] ], dtype='float32')\n",
    "                dx -= [x]\n",
    "                dx *= dx\n",
    "                y = np.array([1, 0], dtype='int')    \n",
    "                self.model.partial_fit(X=dx,\n",
    "                                       y=y,\n",
    "                                       sample_weight=None, # (?)\n",
    "                                       classes=(0, 1))\n",
    "            \n",
    "    def doit():\n",
    "        from collections import Counter\n",
    "        from sklearn.datasets import fetch_covtype\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from math import ceil\n",
    "        import numpy as np\n",
    "        import random\n",
    "        import torch\n",
    "\n",
    "        cov = fetch_covtype()\n",
    "        cov.data = PCA(whiten=True).fit_transform(cov.data)\n",
    "        classes = np.unique(cov.target - 1)\n",
    "        print(Counter(cov.target - 1))\n",
    "        ndata = len(cov.target)\n",
    "        order = np.random.RandomState(seed=42).permutation(ndata)\n",
    "        ntrain = ceil(0.9 * ndata)\n",
    "        Object = lambda **kwargs: type(\"Object\", (), kwargs)()\n",
    "        train = Object(data = cov.data[order[:ntrain]], target = cov.target[order[:ntrain]] - 1)\n",
    "        test = Object(data = cov.data[order[ntrain:]], target = cov.target[order[ntrain:]] - 1)\n",
    "        \n",
    "        input_dim = train.data[0].shape[0]\n",
    "        routerFactory = lambda: FOC.LogisticModel(eta0=0.1, input_dim=input_dim)\n",
    "        scorer = FOC.LearnedEuclideanDistance(eta0=1e-4, input_dim=input_dim)\n",
    "        randomState = random.Random()\n",
    "        randomState.seed(45)\n",
    "        torch.manual_seed(2112)\n",
    "        cmt = CMT(routerFactory=routerFactory, scorer=scorer, alpha=0.25, c=10, d=1, randomState=randomState, \n",
    "                  maxMemories=1000)\n",
    "\n",
    "        print('{:8.8s}\\t{:8.8s}\\t{:10.10s}\\t{:10.10s}'.format(\n",
    "            'n', 'emp loss', 'since last', 'last pred')\n",
    "        )\n",
    "\n",
    "        loss = FOC.EasyAcc()\n",
    "        sincelast = FOC.EasyAcc()\n",
    "\n",
    "        for pno in range(1):\n",
    "            order = np.random.RandomState(seed=42+pno).permutation(len(train.data))\n",
    "            for n, ind in enumerate(order):\n",
    "                t = train.data[ind]\n",
    "                x = tuple(t)\n",
    "                actual = train.target[ind]\n",
    "                \n",
    "                if n == 0:\n",
    "                    pred = 0\n",
    "                else:\n",
    "                    u, z = cmt.query(x, k=1, epsilon=0.0)\n",
    "                    pred = z[0][1] if len(z) else 0\n",
    "                    \n",
    "                loss += 0 if pred == actual else 1\n",
    "                sincelast += 0 if pred == actual else 1\n",
    "                \n",
    "                if (n & (n - 1) == 0): # and n & 0xAAAAAAAA == 0):\n",
    "                    print('{:<8d}\\t{:<8.3f}\\t{:<10.3f}\\t{:<10d}'.format(\n",
    "                                loss.n, loss.mean(), sincelast.mean(), pred),\n",
    "                          flush=True)\n",
    "\n",
    "                    sincelast = FOC.EasyAcc()\n",
    "                    \n",
    "                if n > 0:\n",
    "                    u, z = cmt.query(x, k=2, epsilon=1.0)\n",
    "                    if len(z):\n",
    "                        r = 1 if z[0][1] == actual else -1\n",
    "                        cmt.update(u, x, z, r)\n",
    "\n",
    "                cmt.insert(x, actual)\n",
    "\n",
    "            print('{:<8d}\\t{:<8.3f}\\t{:<10.3f}\\t{:<10d}'.format(\n",
    "                         loss.n, loss.mean(), sincelast.mean(), pred),\n",
    "                   flush=True)                \n",
    "            sincelast = FOC.EasyAcc()\n",
    "            \n",
    "#             preds = cls.predict(np.array([np.outer(d, np.append(d, [1])).ravel() for d in test.data]))\n",
    "#             print(Counter(preds))\n",
    "#             ascores = []\n",
    "#             for b in range(16):\n",
    "#                 bootie = np.random.RandomState(90210+b).choice(len(test.target), replace=True, size=len(test.target))\n",
    "#                 ascores.append(accuracy_score(y_true=test.target[bootie], y_pred=preds[bootie]))\n",
    "\n",
    "#             print(\"test accuracy: {}\".format(np.quantile(ascores, [0.05, 0.5, 0.95])))\n",
    "\n",
    "            pass\n",
    "                        \n",
    "def flass():\n",
    "    import timeit\n",
    "    print(timeit.timeit(FOC.doit, number=1))\n",
    "    \n",
    "flass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
